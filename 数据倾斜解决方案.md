## 数据倾斜

* Hadoop中的数据倾斜现象

  Hive的数据倾斜，一般都发生在 Sql 中 Group 和 On 上，而且和数据逻辑绑定比较深，详细的看日志或者和监控界面的话会发现：
   * 有一个多几个 reduce 卡住
   * 各种 container 报错 OOM
   * 读写的数据量极大，至少远远超过其它正常的 reduce
   * 伴随着数据倾斜，会出现任务被 kill 等各种诡异的表现。
  


* 问题发现与定位

   * 通过 key 统计

      由于数据量巨大，可以采用抽样的方式，对数据进行抽样，统计出现的次数，根据出现次数大小排序取出前几个：

```
df.select("key").sample(false, 0.1)       // 数据采样
.(k => (k, 1)).reduceBykey(_ + _)         // 统计 key 出现的次数
.map(k => (k._2, k._1))                   // 根据 key 出现次数进行排序
.sortByKey(false).take(10)                // 取前 10 个
```

* 如何缓解数据倾斜

   * 基本思路

      * 业务逻辑: 我们从业务逻辑的层面上来优化数据倾斜，比如要统计不同城市的订单情况，那么我们单独对这一线城市来做 count，最后和其它城市做整合。
      
   一般从业务逻辑上很少能解决问题，原因是大部分的业务确实会产生导致数据倾斜业务数据数据，即Key不均匀
      
      * 参数调优: Hadoop 和 Spark 都自带了很多的参数和机制来调节数据倾斜，合理利用它们就能解决大部分问题。

   * map join 方式
count distinct 的操作，先转成 group，再 count
参数调优
set hive.map.aggr=true
set hive.groupby.skewindata=true
left semi jion 的使用
设置 map 端输出、中间结果压缩。（不完全是解决数据倾斜的问题，但是减少了 IO 读写和网络传输，能提高很多效率）
