## 数据倾斜

* Hadoop中的数据倾斜现象

  Hive的数据倾斜，一般都发生在 Sql 中 **Group 和 On** 上，而且和数据逻辑绑定比较深，详细的看日志或者和监控界面的话会发现：
   * 有一个或几个 reduce 卡住
   * 各种 container 报错 OOM
   * 读写的数据量极大，至少远远超过其它正常的 reduce
   * 伴随着数据倾斜，会出现任务被 kill 等各种诡异的表现。
  


* 问题发现与定位

   * 通过 key 统计

      由于数据量巨大，可以采用抽样的方式，对数据进行抽样，统计出现的次数，根据出现次数大小排序取出前几个，Spark中可以这么操作：

```
df.select("key").sample(false, 0.1)       // 数据采样
.(k => (k, 1)).reduceBykey(_ + _)         // 统计 key 出现的次数
.map(k => (k._2, k._1))                   // 根据 key 出现次数进行排序
.sortByKey(false).take(10)                // 取前 10 个
```

* 如何缓解数据倾斜

   * 基本思路

      * 从业务逻辑解决: 我们从业务逻辑的层面上来优化数据倾斜，比如要统计不同城市的订单情况，那么我们单独对这一线城市来做 count，最后和其它城市做整合。
      
      * 从程序调优: Hadoop 和 Spark 都自带了很多的参数和机制来调节数据倾斜，合理利用它们就能解决大部分问题。
         * set hive.map.aggr=true，在map中会做部分聚集操作，效率更高但需要更多的内存
         * set hive.exec.parallel.thread.number=8;设置task的并行度
         * hive.groupby.skewindata=true: 有数据倾斜的时候进行负载均衡，当选项设定为true，生成的查询计划会有两个MRJob。第一个MRJob 中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的GroupBy Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MRJob再根据预处理的数据结果按照GroupBy Key分布到Reduce中（这个过程可以保证相同的GroupBy Key被分布到同一个Reduce中），最后完成最终的聚合操作
         * set mapreduce.map.output.compress=true;设置 map 端输出、中间结果压缩。（不完全是解决数据倾斜的问题，但是减少了 IO 读写和网络传输，能提高很多效率）
         * map join 方式
         * count distinct 的操作，先转成 group，再 count
